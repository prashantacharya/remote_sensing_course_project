{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from rasterio.errors import NotGeoreferencedWarning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from rasterio.windows import Window\n",
    "from scipy.ndimage import generic_filter\n",
    "\n",
    "# Suppress NotGeoreferencedWarning\n",
    "warnings.simplefilter(\"ignore\", NotGeoreferencedWarning)\n",
    "\n",
    "# # Paths to the TIFF images for different years\n",
    "image_paths = {\n",
    "    '2018': 'dataset/2018/m_3912112_sw_10_060_20180718.tif',\n",
    "    '2022': 'dataset/2022/m_3912112_sw_10_060_20220714.tif'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Helper Functions\n",
    "def read_tiff(filename):\n",
    "    \"\"\"\n",
    "    Reads the entire TIFF image.\n",
    "    \"\"\"\n",
    "    with rasterio.open(filename) as src:\n",
    "        image = src.read()\n",
    "    return image\n",
    "\n",
    "def calculate_ndvi(nir, red):\n",
    "    \"\"\"Calculates NDVI using NIR and red bands.\"\"\"\n",
    "    return (nir.astype(float) - red.astype(float)) / (nir + red + 1e-8)\n",
    "\n",
    "def add_texture(image, window_size=3):\n",
    "    \"\"\"Adds texture feature to the image.\"\"\"\n",
    "    texture = generic_filter(image, np.std, size=window_size)\n",
    "    return np.dstack((image, texture))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Data Preparation\n",
    "# Read subsets from all years\n",
    "subsets = {year: read_tiff(path) for year, path in image_paths.items()}\n",
    "\n",
    "# Calculate NDVI for all years\n",
    "ndvis = {}\n",
    "for year, subset in subsets.items():\n",
    "    red, nir = subset[0], subset[3]  # Assuming bands are in order: R, G, B, NIR\n",
    "    ndvis[year] = calculate_ndvi(nir, red)\n",
    "\n",
    "# Prepare features and ground truth for each year\n",
    "predictions = {}\n",
    "ground_truths = {}\n",
    "\n",
    "for year in ['2018', '2022']:\n",
    "    rgb = np.moveaxis(subsets[year][:3], 0, -1)\n",
    "    features = add_texture(rgb).reshape(-1, 4)\n",
    "    \n",
    "    if year == '2018':\n",
    "        ground_truths[year] = np.where(ndvis['2018'] > 0.3, 1, 0).ravel()\n",
    "    else:\n",
    "        current_year_ndvi = ndvis['2022'] > 0.3\n",
    "        previous_year_ndvi = ndvis['2018'] <= 0.3\n",
    "        print(\"HERE\")\n",
    "        ground_truths[year] = (current_year_ndvi & previous_year_ndvi).astype(int).ravel()\n",
    "        print(\"HERE 2\")\n",
    "\n",
    "    min_length = min(ground_truths[year].size, features.shape[0])\n",
    "    features = features[:min_length]\n",
    "    ground_truths[year] = ground_truths[year][:min_length]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 Apply model\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Initialize predictions dictionary to store results for both years\n",
    "predictions = {}\n",
    "\n",
    "for year in ['2018', '2022']:\n",
    "    # Scale features for each year (using features from the last processed year)\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_scaled, ground_truths[year], test_size=0.2, random_state=42)\n",
    "\n",
    "    # Random Forest Classifier\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10, class_weight=\"balanced\", n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Store predictions for both years in the predictions dictionary\n",
    "    predictions[f'{year}_rf'] = rf.predict(features_scaled)\n",
    "\n",
    "    # Gradient Boosting Classifier\n",
    "    from sklearn.utils.class_weight import compute_sample_weight\n",
    "    \n",
    "    # Compute sample weights to balance classes\n",
    "    sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "    \n",
    "    gb = GradientBoostingClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "    gb.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "    \n",
    "    # Store predictions for both years in the predictions dictionary\n",
    "    predictions[f'{year}_gb'] = gb.predict(features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Change Detection and Visualization\n",
    "# Compute change detection (e.g., from 2018 to 2022)\n",
    "deforestation_rf = (predictions['2018_rf'] == 1) & (predictions['2022_rf'] == 0)\n",
    "reforestation_rf = (predictions['2018_rf'] == 0) & (predictions['2022_rf'] == 1)\n",
    "no_change_rf = (predictions['2018_rf'] == predictions['2022_rf'])\n",
    "\n",
    "deforestation_gb = (predictions['2018_gb'] == 1) & (predictions['2022_gb'] == 0)\n",
    "reforestation_gb = (predictions['2018_gb'] == 0) & (predictions['2022_gb'] == 1)\n",
    "no_change_gb = (predictions['2018_gb'] == predictions['2022_gb'])\n",
    "\n",
    "# Calculate total pixels and pixel categories\n",
    "total_pixels = ndvis['2018'].size\n",
    "\n",
    "print(\"Random Forest Results:\")\n",
    "print(f\"Deforested Pixels: {np.sum(deforestation_rf)} ({(np.sum(deforestation_rf) / total_pixels) * 100:.2f}%)\")\n",
    "print(f\"Reforested Pixels: {np.sum(reforestation_rf)} ({(np.sum(reforestation_rf) / total_pixels) * 100:.2f}%)\")\n",
    "print(f\"Unchanged Pixels: {np.sum(no_change_rf)} ({(np.sum(no_change_rf) / total_pixels) * 100:.2f}%)\")\n",
    "\n",
    "print(\"\\nGradient Boosting Results:\")\n",
    "print(f\"Deforested Pixels: {np.sum(deforestation_gb)} ({(np.sum(deforestation_gb) / total_pixels) * 100:.2f}%)\")\n",
    "print(f\"Reforested Pixels: {np.sum(reforestation_gb)} ({(np.sum(reforestation_gb) / total_pixels) * 100:.2f}%)\")\n",
    "print(f\"Unchanged Pixels: {np.sum(no_change_gb)} ({(np.sum(no_change_gb) / total_pixels) * 100:.2f}%)\")\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(20, 30))\n",
    "\n",
    "# Plot original images\n",
    "axs[0, 0].imshow(np.moveaxis(subsets['2018'][:3], 0, -1))\n",
    "axs[0, 0].set_title('Original Image 2018')\n",
    "axs[0, 0].axis('off')\n",
    "\n",
    "axs[0, 1].imshow(np.moveaxis(subsets['2022'][:3], 0, -1))\n",
    "axs[0, 1].set_title('Original Image 2022')\n",
    "axs[0, 1].axis('off')\n",
    "\n",
    "# Plot NDVI images\n",
    "axs[1, 0].imshow(ndvis['2018'], cmap='RdYlGn', vmin=-1, vmax=1)\n",
    "axs[1, 0].set_title('NDVI 2018')\n",
    "axs[1, 0].axis('off')\n",
    "\n",
    "axs[1, 1].imshow(ndvis['2022'], cmap='RdYlGn', vmin=-1, vmax=1)\n",
    "axs[1, 1].set_title('NDVI 2022')\n",
    "axs[1, 1].axis('off')\n",
    "\n",
    "# Plot Random Forest results\n",
    "rf_result = np.zeros(ndvis['2018'].shape, dtype=int)\n",
    "rf_result[deforestation_rf.reshape(ndvis['2018'].shape)] = 1  # Red for deforestation\n",
    "rf_result[reforestation_rf.reshape(ndvis['2018'].shape)] = 2  # Green for reforestation\n",
    "rf_result[no_change_rf.reshape(ndvis['2018'].shape)] = 3  # Blue for no change\n",
    "\n",
    "axs[2, 0].imshow(rf_result, cmap=plt.cm.colors.ListedColormap(['white', 'red', 'green', 'blue']))\n",
    "axs[2, 0].set_title('Random Forest Results')\n",
    "axs[2, 0].axis('off')\n",
    "\n",
    "# Plot Gradient Boosting results\n",
    "gb_result = np.zeros(ndvis['2018'].shape, dtype=int)\n",
    "gb_result[deforestation_gb.reshape(ndvis['2018'].shape)] = 1  # Red for deforestation\n",
    "gb_result[reforestation_gb.reshape(ndvis['2018'].shape)] = 2  # Green for reforestation\n",
    "gb_result[no_change_gb.reshape(ndvis['2018'].shape)] = 3  # Blue for no change\n",
    "\n",
    "axs[2, 1].imshow(gb_result, cmap=plt.cm.colors.ListedColormap(['white', 'red', 'green', 'blue']))\n",
    "axs[2, 1].set_title('Gradient Boosting Results')\n",
    "axs[2, 1].axis('off')\n",
    "\n",
    "# Add a common legend\n",
    "legend_elements = [plt.Rectangle((0,0),1,1, facecolor='red', edgecolor='none', label='Deforestation'),\n",
    "                   plt.Rectangle((0,0),1,1, facecolor='green', edgecolor='none', label='Reforestation'),\n",
    "                   plt.Rectangle((0,0),1,1, facecolor='blue', edgecolor='none', label='No Change'),\n",
    "                   plt.Rectangle((0,0),1,1, facecolor='white', edgecolor='none', label='Unclassified')]\n",
    "\n",
    "fig.legend(handles=legend_elements, loc='lower center', ncol=4, bbox_to_anchor=(0.5, -0.05))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Areas that were not forest in either year (e.g., water bodies, urban areas, or bare soil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Model Evaluation\n",
    "def print_metrics(y_true, y_pred, model_name):\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "    print(\"F1-score:\", f1_score(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\n\")\n",
    "\n",
    "for year in ['2018', '2022']:\n",
    "    print(f\"Year: {year}\")\n",
    "    print_metrics(ground_truths[year], predictions[f'{year}_rf'], \"Random Forest\")\n",
    "    print_metrics(ground_truths[year], predictions[f'{year}_gb'], \"Gradient Boosting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "\n",
    "b = np.where(a > 1, 1, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_sensing_change_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
